{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1><a href=\"index.ipynb\">Knowledge Discovery in Digital Humanities</a></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h2>Class 17. Word tagging and categorization</h2>\n",
    "    <img src=\"img/tag.svg\" width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Table of contents\n",
    "\n",
    "- [Lexical categories](#Lexical-categories)\n",
    "- [POS tagger](#POS-tagger)\n",
    "- [Automatic tagging](#Automatic-tagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Lexical categories\n",
    "\n",
    "- **nouns**: people, places, things, concepts\n",
    "- **verbs**: actions\n",
    "- **adjectives**: describes nouns\n",
    "- **adverbs**: modifies adjectives and verbs\n",
    "- ...\n",
    "\n",
    "<br/>\n",
    "<div align=\"center\">\n",
    "    <figure>\n",
    "        <img src=\"img/pos.png\" width=\"800\">\n",
    "        <figcaption>Lexical categories</figcaption>\n",
    "    </figure>\n",
    "</div>\n",
    "\n",
    "- These word classes are also known as parts-of-speech (POS)\n",
    "- They arise from simple analysis of the distribution of words in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###POS tagger\n",
    "\n",
    "The process of classifying words into their parts-of-speech and labeling them accordingly is known as *part-of-speech tagging*, *POS tagging*, or simply *tagging*.\n",
    "\n",
    "POS tagging is the third step in the typical natural language processing (NLP) pipeline, following tokenization.\n",
    "\n",
    "<br/>\n",
    "<div align=\"center\">\n",
    "    <figure>\n",
    "        <img src=\"img/nlp-pipeline.png\" width=\"600\">\n",
    "        <figcaption>NLP pipeline</figcaption>\n",
    "    </figure>\n",
    "</div>\n",
    "\n",
    "A POS tagger processes a sequence of words, and attaches a part of speech tag to each word. Steps:\n",
    "1. Tokenization\n",
    "2. Tagging\n",
    "\n",
    "Note: import the `nltk` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and run only once the next code (use an IPython shell rather than an IPython notebook)...\n",
    "```\n",
    "nltk.download()\n",
    "```\n",
    "... choose `d) Download` for the downloader and then `all` as identifier to download all packages. This will download all the corpora and data needed to work with `nltk`.\n",
    "\n",
    "Example 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'And now for something completely different'\n",
    "tokens = nltk.word_tokenize(text)\n",
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <caption>Meaning of abbreviations (I)</caption>\n",
    "    <thead>\n",
    "        <th>Abbreviation</th><th>Lexical catefory</th>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr><td>CC</td><td>coordinating conjunction</td></tr>\n",
    "        <tr><td>RB</td><td>adverb</td></tr>\n",
    "        <tr><td>IN</td><td>preposition</td></tr>\n",
    "        <tr><td>NN</td><td>noun</td></tr>\n",
    "        <tr><td>JJ</td><td>adjective</td></tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PRP'),\n",
       " ('refuse', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('permit', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('obtain', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('refuse', 'NN'),\n",
       " ('permit', 'NN')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'They refuse to permit us to obtain the refuse permit'\n",
    "tokens = nltk.word_tokenize(text)\n",
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <caption>Meaning of abbreviations (II)</caption>\n",
    "    <thead>\n",
    "        <th>Abbreviation</th><th>Lexical catefory</th>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr><td>PRP</td><td>personal pronoun</td></tr>\n",
    "        <tr><td>VBP</td><td>verb in present tense</td></tr>\n",
    "        <tr><td>TO</td><td>preposition *to*</td></tr>\n",
    "        <tr><td>VB</td><td>verb</td></tr>\n",
    "        <tr><td>DT</td><td>determiner</td></tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that *refuse* and *permit* both appear as a present tense verb (VBP) and a noun (NN). NLTK provides documentation for each tag, which can be queried using the function `nltk.help.upenn_tagset(tag)`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('RB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Automatic tagging\n",
    "\n",
    "- The tag of a word depends on the word itself and its context within a sentence\n",
    "- Therefore, working with data at the level of complete (tagged) sentences rather than independent (tagged) words\n",
    "\n",
    "####Dataset\n",
    "[Brown Corpus](http://www.helsinki.fi/varieng/CoRD/corpora/BROWN/). The *Brown University Standard Corpus of Present-Day American English* (or just Brown Corpus) was the first computer-readable general corpus of texts prepared for linguistic research on modern English. It was compiled by W. Nelson Francis and Henry Kuƒçera at Brown University in the 1960s and contains of over 1 million words (500 samples of 2000+ words each) of running text of edited English prose printed in the United States during the calendar year 1961.\n",
    "\n",
    "Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "brown_sents = brown.sents(categories='news')\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'The',\n",
       " u'Fulton',\n",
       " u'County',\n",
       " u'Grand',\n",
       " u'Jury',\n",
       " u'said',\n",
       " u'Friday',\n",
       " u'an',\n",
       " u'investigation',\n",
       " u'of',\n",
       " u\"Atlanta's\",\n",
       " u'recent',\n",
       " u'primary',\n",
       " u'election',\n",
       " u'produced',\n",
       " u'``',\n",
       " u'no',\n",
       " u'evidence',\n",
       " u\"''\",\n",
       " u'that',\n",
       " u'any',\n",
       " u'irregularities',\n",
       " u'took',\n",
       " u'place',\n",
       " u'.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'The', u'AT'),\n",
       " (u'Fulton', u'NP-TL'),\n",
       " (u'County', u'NN-TL'),\n",
       " (u'Grand', u'JJ-TL'),\n",
       " (u'Jury', u'NN-TL'),\n",
       " (u'said', u'VBD'),\n",
       " (u'Friday', u'NR'),\n",
       " (u'an', u'AT'),\n",
       " (u'investigation', u'NN'),\n",
       " (u'of', u'IN'),\n",
       " (u\"Atlanta's\", u'NP$'),\n",
       " (u'recent', u'JJ'),\n",
       " (u'primary', u'NN'),\n",
       " (u'election', u'NN'),\n",
       " (u'produced', u'VBD'),\n",
       " (u'``', u'``'),\n",
       " (u'no', u'AT'),\n",
       " (u'evidence', u'NN'),\n",
       " (u\"''\", u\"''\"),\n",
       " (u'that', u'CS'),\n",
       " (u'any', u'DTI'),\n",
       " (u'irregularities', u'NNS'),\n",
       " (u'took', u'VBD'),\n",
       " (u'place', u'NN'),\n",
       " (u'.', u'.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Default tagger\n",
    "- Assigns the same tag to each token\n",
    "- Choses the most likely tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'AT',\n",
       " u'NP-TL',\n",
       " u'NN-TL',\n",
       " u'JJ-TL',\n",
       " u'NN-TL',\n",
       " u'VBD',\n",
       " u'NR',\n",
       " u'AT',\n",
       " u'NN',\n",
       " u'IN']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = [tag for (word, tag) in brown.tagged_words(categories='news')]\n",
    "tags[: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({u'NN': 13162, u'IN': 10616, u'AT': 8893, u'NP': 6866, u',': 5133, u'NNS': 5066, u'.': 4452, u'JJ': 4392, u'CC': 2664, u'VBD': 2524, ...})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'NN'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(tags).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'NN'),\n",
       " ('do', 'NN'),\n",
       " ('not', 'NN'),\n",
       " ('like', 'NN'),\n",
       " ('green', 'NN'),\n",
       " ('eggs', 'NN'),\n",
       " ('and', 'NN'),\n",
       " ('ham', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('I', 'NN'),\n",
       " ('do', 'NN'),\n",
       " ('not', 'NN'),\n",
       " ('like', 'NN'),\n",
       " ('them', 'NN'),\n",
       " ('Sam', 'NN'),\n",
       " ('I', 'NN'),\n",
       " ('am', 'NN'),\n",
       " ('!', 'NN')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'I do not like green eggs and ham, I do not like them Sam I am!'\n",
    "tokens = nltk.word_tokenize(text)\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "default_tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unknown words will be nouns (as it happens, most new words are nouns)\n",
    "\n",
    "Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13089484257215028"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Regular expression tagger\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
